{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import joblib\n",
    "import warnings\n",
    "import gc\n",
    "import wget\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download the helper script\n",
    "wget.download(\"https://raw.githubusercontent.com/yogawicaksana/helper_prabowo/main/helper_prabowo_ml.py\", out=\"helper_prabowo_ml.py\")\n",
    "\n",
    "# Import the helper functions\n",
    "from helper_prabowo_ml import (\n",
    "    clean_html, punct, remove_digits, remove_links, \n",
    "    remove_special_characters, remove_, removeStopWords, \n",
    "    lower, email_address, non_ascii\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If there was justice @SkyNews and other #MSM w...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The weakening of the US dollar continues to be...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ZRVGaming No, it looks great actually; it's j...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jody was a loser but he had everything a nigga...</td>\n",
       "      <td>ethnicity/race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@PRM83 @BuffaloSpartan @MSUSpartansSZN @MattC2...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              label\n",
       "0  If there was justice @SkyNews and other #MSM w...           religion\n",
       "1  The weakening of the US dollar continues to be...  not_cyberbullying\n",
       "2  @ZRVGaming No, it looks great actually; it's j...  not_cyberbullying\n",
       "3  Jody was a loser but he had everything a nigga...     ethnicity/race\n",
       "4  @PRM83 @BuffaloSpartan @MSUSpartansSZN @MattC2...  not_cyberbullying"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Dataset/OriginalDataset.csv')\n",
    "df = df.sample(n=20000).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_text(data,col):\n",
    "    data[col] = data[col].apply(func=remove_)\n",
    "    data[col] = data[col].apply(func=remove_digits)\n",
    "    data[col] = data[col].apply(func=remove_links)\n",
    "    data[col] = data[col].apply(func=remove_special_characters)\n",
    "    data[col] = data[col].apply(func=removeStopWords)\n",
    "    data[col] = data[col].apply(func=punct)\n",
    "    data[col] = data[col].apply(func=email_address)\n",
    "    data[col] = data[col].apply(func=non_ascii)\n",
    "    data[col] = data[col].apply(func=clean_html)\n",
    "    data[col] = data[col].apply(func=lower)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if justice skynews msm would shut work ed whit...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the weakening us dollar continues concern many...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zrvgaming no looks great actually portable hou...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jody loser everything nigga wanted besides car...</td>\n",
       "      <td>ethnicity/race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prm buffalospartan msuspartansszn mattc graham...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              label\n",
       "0  if justice skynews msm would shut work ed whit...           religion\n",
       "1  the weakening us dollar continues concern many...  not_cyberbullying\n",
       "2  zrvgaming no looks great actually portable hou...  not_cyberbullying\n",
       "3  jody loser everything nigga wanted besides car...     ethnicity/race\n",
       "4  prm buffalospartan msuspartansszn mattc graham...  not_cyberbullying"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df = clean_text(df,'text')\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n",
      "Device Name: NVIDIA GeForce MX350\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is NOT available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sreeniketh/cyberbullying_sentiment_dsce_2023')\n",
    "distilbert = TFAutoModelForSequenceClassification.from_pretrained('sreeniketh/cyberbullying_sentiment_dsce_2023',from_pt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(preprocessed_df,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_length = 85\n",
    "\n",
    "X_train = tokenizer(text=train_df['text'].tolist(),\n",
    "                   max_length=max_length,\n",
    "                   padding=True,\n",
    "                   truncation=True,\n",
    "                   add_special_tokens=True,\n",
    "                   return_tensors='tf',\n",
    "                   return_attention_mask=True,\n",
    "                   return_token_type_ids=False,\n",
    "                   verbose=1)\n",
    "\n",
    "X_test = tokenizer(text=test_df['text'].tolist(),\n",
    "                  max_length=max_length,\n",
    "                  padding=True,\n",
    "                  truncation=True,\n",
    "                  add_special_tokens=True,\n",
    "                  return_tensors='tf',\n",
    "                  return_attention_mask=True,\n",
    "                  return_token_type_ids=False,\n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode labels and store mapping  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ethnicity/race',\n",
       " 1: 'gender/sexual',\n",
       " 2: 'not_cyberbullying',\n",
       " 3: 'religion'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "train_df.label = encoder.fit_transform(train_df.label)\n",
    "test_df.label = encoder.transform(test_df.label)\n",
    "\n",
    "encoded_labels = dict()\n",
    "\n",
    "for idx, label in enumerate(encoder.classes_):\n",
    "    encoded_labels[idx] = label\n",
    "\n",
    "encoded_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_ids = Input(shape=(max_length,),name='input_ids',dtype=tf.int32)\n",
    "attention_mask = Input(shape=(max_length,),name='attention_mask',dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract embeddings from DistilBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'tf_distil_bert_for_sequence_classification' (type TFDistilBertForSequenceClassification).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_distil_bert_for_sequence_classification' (type TFDistilBertForSequenceClassification):\n  • input_ids=<KerasTensor shape=(None, 85), dtype=int32, sparse=False, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, 85), dtype=int32, sparse=False, name=attention_mask>\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • labels=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# 0 -> final hidden state output, 1 -> pooling output\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\modeling_tf_utils.py:436\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m--> 436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m \u001b[43minput_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args_and_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\modeling_tf_utils.py:513\u001b[0m, in \u001b[0;36minput_processing\u001b[1;34m(func, config, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m         output[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 513\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(main_input, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(main_input):\n\u001b[0;32m    517\u001b[0m         \u001b[38;5;66;03m# EagerTensors don't allow to use the .name property so we check for a real Tensor\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_distil_bert_for_sequence_classification' (type TFDistilBertForSequenceClassification).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_distil_bert_for_sequence_classification' (type TFDistilBertForSequenceClassification):\n  • input_ids=<KerasTensor shape=(None, 85), dtype=int32, sparse=False, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, 85), dtype=int32, sparse=False, name=attention_mask>\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • labels=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "embeddings = distilbert(input_ids,attention_mask=attention_mask)[0] # 0 -> final hidden state output, 1 -> pooling output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output = Flatten()(embeddings)\n",
    "output = Dense(units=128,activation='relu')(output)\n",
    "output = BatchNormalization()(output)\n",
    "output = Dropout(0.3)(output)\n",
    "output = Dense(units=64,activation='relu')(output)\n",
    "output = BatchNormalization()(output)\n",
    "output = Dropout(0.2)(output)\n",
    "output = Dense(units=32,activation='relu')(output)\n",
    "output = BatchNormalization()(output)\n",
    "output = Dropout(0.1)(output)\n",
    "output = Dense(units=4,activation='softmax')(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[input_ids,attention_mask],outputs=output)\n",
    "model.layers[2].trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_model(model,to_file='model.png',show_shapes=True,dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer and class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "adam = AdamW(learning_rate=5e-5, weight_decay=0.01, epsilon=2e-7, clipnorm=1.0)\n",
    "class_weights = {0: 0.3, 1: 0.25, 2: 0.15, 3: 0.3}\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=adam,\n",
    "    metrics=[SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate decay function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def time_based_decay(epoch, lr):\n",
    "    decay_rate = 1e-5\n",
    "    decay_epoch = 10\n",
    "    return lr * (1 / (1 + decay_rate * epoch / decay_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_sparse_categorical_accuracy',mode='max',patience=5,restore_best_weights=True,verbose=1)\n",
    "ls = LearningRateScheduler(time_based_decay,verbose=1)\n",
    "mc = ModelCheckpoint(filepath='cyberbullying_classifier.keras',monitor='val_sparse_categorical_accuracy',save_best_only=True,mode='max',verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "r = model.fit(x={'input_ids': X_train['input_ids'], 'attention_mask': X_train['attention_mask']},\n",
    "              y=train_df.label,\n",
    "              batch_size=256,\n",
    "              epochs=15,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=({'input_ids': X_test['input_ids'], 'attention_mask': X_test['attention_mask']},test_df.label),\n",
    "              callbacks=[es,ls,mc]\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot training loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(r.history['loss'],'r',label='Train Loss')\n",
    "plt.plot(r.history['val_loss'],'b',label='Test Loss')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Graph')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(r.history['sparse_categorical_accuracy'],'r',label='Train Accuracy')\n",
    "plt.plot(r.history['val_sparse_categorical_accuracy'],'b',label='Test Accuracy')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Graph')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate({'input_ids': X_test['input_ids'],'attention_mask': X_test['attention_mask']},test_df.label)\n",
    "print(\"Sparse Categorical Crossentropy Loss:\", round(loss,2))\n",
    "print(\"Sparse Categorical Accuracy:\", round(acc*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict({'input_ids': X_test['input_ids'],'attention_mask': X_test['attention_mask']})\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "cm = confusion_matrix(test_df.label, test_predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "heatmap = sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', xticklabels=True, yticklabels=True)\n",
    "colorbar = heatmap.collections[0].colorbar\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_df.label,test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save essential files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "preprocessed_df.to_csv('../Dataset/PreprocessedDataset.csv', index=False)\n",
    "print(\"Preprocessed dataframe saved as CSV\")\n",
    "\n",
    "with open('../Artifacts/X_train.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train, f)\n",
    "print(\"X_train saved as pickle\")\n",
    "\n",
    "with open('../Artifacts/X_test.pkl', 'wb') as f:\n",
    "    pickle.dump(X_test, f)\n",
    "print(\"X_test saved as pickle\")\n",
    "\n",
    "with open('../Artifacts/LabelEncoder.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder, f)\n",
    "print(\"Label encoder saved using pickle\")\n",
    "\n",
    "model.save('../Artifacts/CyberbullyingClassifier.keras')\n",
    "print(\"Model saved as .keras\")\n",
    "\n",
    "with open('../Artifacts/TrainingHistory.pkl', 'wb') as f:\n",
    "    pickle.dump(r.history, f)\n",
    "print(\"Training history saved as pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load essential files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "preprocessed_df = pd.read_csv('../Dataset/PreprocessedDataset.csv')\n",
    "print(\"Preprocessed dataframe loaded from CSV\")\n",
    "\n",
    "with open('../Artifacts/X_train.pkl', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "print(\"X_train loaded from pickle\")\n",
    "\n",
    "with open('../Artifacts/X_test.pkl', 'rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "print(\"X_test loaded from pickle\")\n",
    "\n",
    "with open('../Artifacts/LabelEncoder.pkl', 'rb') as f:\n",
    "    encoder = pickle.load(f)\n",
    "print(\"Label encoder loaded using pickle\")\n",
    "\n",
    "with open('../Artifacts/TrainingHistory.pkl', 'rb') as f:\n",
    "    training_history = pickle.load(f)\n",
    "print(\"Training history loaded from pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "\n",
    "custom_objects = {\n",
    "    'TFDistilBertForSequenceClassification': TFDistilBertForSequenceClassification\n",
    "}\n",
    "\n",
    "model = load_model('../Artifacts/FineTunedBERT.keras', custom_objects=custom_objects)\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3560090,
     "sourceId": 6200876,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
